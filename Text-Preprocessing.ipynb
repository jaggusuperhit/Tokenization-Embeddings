{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XQ7oje4Bik85"
   },
   "source": [
    "## Dataset:\n",
    "https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Kaggle API Credentials\n",
    "\n",
    "To use the Kaggle API, you need to set up your credentials. You can get your API key from your Kaggle account settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle credentials have been set for this session.\n"
     ]
    }
   ],
   "source": [
    "# Set up Kaggle credentials directly\n",
    "os.environ['KAGGLE_USERNAME'] = 'surajnamdeojagtap'\n",
    "os.environ['KAGGLE_KEY'] = '0c3f14a7cd787f54b1a7a0e043f6c29d'\n",
    "print(\"Kaggle credentials have been set for this session.\")\n",
    "\n",
    "# Create a directory for the dataset if it doesn't exist\n",
    "os.makedirs(\"data\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching Data Directly Using Kaggle API\n",
    "\n",
    "Instead of downloading the dataset manually, we'll use the Kaggle API to fetch it directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using kaggle API to download dataset...\n",
      "Dataset URL: https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\n",
      "Dataset downloaded successfully to 'data' directory\n"
     ]
    }
   ],
   "source": [
    "# Check if kaggle is installed\n",
    "try:\n",
    "    import kaggle\n",
    "    # Method 1: Using kaggle API\n",
    "    print(\"Using kaggle API to download dataset...\")\n",
    "    kaggle.api.dataset_download_files(\n",
    "        \"lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\",\n",
    "        path=\"data\",\n",
    "        unzip=True\n",
    "    )\n",
    "    print(\"Dataset downloaded successfully to 'data' directory\")\n",
    "except ImportError:\n",
    "    print(\"Kaggle module not found. Please download the dataset manually from:\")\n",
    "    print(\"https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\")\n",
    "    print(\"and place it in a 'data' directory.\")\n",
    "    import os\n",
    "    os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "# Set the path to the downloaded dataset\n",
    "path = \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded with shape: (50000, 2)\n",
      "Dataset loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data_path = os.path.join(path, \"IMDB Dataset.csv\")\n",
    "df = pd.read_csv(data_path)\n",
    "print(f\"Dataset loaded with shape: {df.shape}\")\n",
    "\n",
    "# Check if the dataset was loaded correctly\n",
    "if df.shape[0] > 0:\n",
    "    print(\"Dataset loaded successfully!\")\n",
    "else:\n",
    "    print(\"Error: Dataset is empty.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For demonstration purposes, let's work with a smaller sample\n",
    "df = df.head(100)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2904AVZxfXI3"
   },
   "source": [
    "# Text Preprocessing Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Convert to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.<br /><br />OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing & arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. As for the shots with Jake: just ignore them.\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display an example review before preprocessing\n",
    "df['review'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all text to lowercase\n",
    "df['review'] = df['review'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"basically there's a family where a little boy (jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />this movie is slower than a soap opera... and suddenly, jake decides to become rambo and kill the zombie.<br /><br />ok, first of all when you're going to make a film you must decide if its a thriller or a drama! as a drama the movie is watchable. parents are divorcing & arguing like in real life. and then we have jake with his closet which totally ruins all the film! i expected to see a boogeyman similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. as for the shots with jake: just ignore them.\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the same review after lowercase conversion\n",
    "df['review'][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q6PdP4pvfXJD"
   },
   "source": [
    "## 2. Remove HTML tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html_tags(text):\n",
    "    \"\"\"Remove HTML tags from text\"\"\"\n",
    "    pattern = re.compile('<.*?>')\n",
    "    return pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply HTML tag removal\n",
    "df['review'] = df['review'].apply(remove_html_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"basically there's a family where a little boy (jake) thinks there's a zombie in his closet & his parents are fighting all the time.this movie is slower than a soap opera... and suddenly, jake decides to become rambo and kill the zombie.ok, first of all when you're going to make a film you must decide if its a thriller or a drama! as a drama the movie is watchable. parents are divorcing & arguing like in real life. and then we have jake with his closet which totally ruins all the film! i expected to see a boogeyman similar movie, and instead i watched a drama with some meaningless thriller spots.3 out of 10 just for the well playing parents & descent dialogs. as for the shots with jake: just ignore them.\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the review after HTML tag removal\n",
    "df['review'][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(text):\n",
    "    pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = 'Check out my youtube https://www.youtube.com/dswithbappy dswithbappy'\n",
    "text2 = 'Check out my linkedin https://www.linkedin.com/in/boktiarahmed73/'\n",
    "text3 = 'Google search here www.google.com'\n",
    "text4 = 'For data click https://www.kaggle.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Check out my linkedin '"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_url(text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Punctuation handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string,time\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exclude = string.punctuation\n",
    "exclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc(text):\n",
    "    for char in exclude:\n",
    "        text = text.replace(char,'')\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'string. With. Punctuation?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "string With Punctuation\n",
      "54.09717559814453\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(remove_punc(text))\n",
    "time1 = time.time() - start\n",
    "print(time1*50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc1(text):\n",
    "    return text.translate(str.maketrans('', '', exclude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "remove_punc1(text)\n",
    "time2 = time.time() - start\n",
    "print(time2*50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method 2 is too fast to measure accurately\n"
     ]
    }
   ],
   "source": [
    "# Compare execution times (avoid division by zero)\n",
    "if time2 > 0:\n",
    "    print(f\"Method 1 is {time1/time2:.2f} times slower than Method 2\")\n",
    "else:\n",
    "    print(\"Method 2 is too fast to measure accurately\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'probably my all-time favorite movie, a story of selflessness, sacrifice and dedication to a noble cause, but it\\'s not preachy or boring. it just never gets old, despite my having seen it some 15 or more times in the last 25 years. paul lukas\\' performance brings tears to my eyes, and bette davis, in one of her very few truly sympathetic roles, is a delight. the kids are, as grandma says, more like \"dressed-up midgets\" than children, but that only makes them more fun to watch. and the mother\\'s slow awakening to what\\'s happening in the world and under her own roof is believable and startling. if i had a dozen thumbs, they\\'d all be \"up\" for this movie.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'probably my alltime favorite movie a story of selflessness sacrifice and dedication to a noble cause but its not preachy or boring it just never gets old despite my having seen it some 15 or more times in the last 25 years paul lukas performance brings tears to my eyes and bette davis in one of her very few truly sympathetic roles is a delight the kids are as grandma says more like dressedup midgets than children but that only makes them more fun to watch and the mothers slow awakening to whats happening in the world and under her own roof is believable and startling if i had a dozen thumbs theyd all be up for this movie'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_punc1(df['review'][5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chat conversation handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FYI': 'For Your Information',\n",
       " 'ASAP': 'As Soon As Possible',\n",
       " 'BRB': 'Be Right Back',\n",
       " 'BTW': 'By The Way',\n",
       " 'OMG': 'Oh My God',\n",
       " 'IMO': 'In My Opinion',\n",
       " 'LOL': 'Laugh Out Loud',\n",
       " 'TTYL': 'Talk To You Later',\n",
       " 'GTG': 'Got To Go',\n",
       " 'TTYT': 'Talk To You Tomorrow',\n",
       " 'IDK': \"I Don't Know\",\n",
       " 'TMI': 'Too Much Information',\n",
       " 'IMHO': 'In My Humble Opinion',\n",
       " 'ICYMI': 'In Case You Missed It',\n",
       " 'AFAIK': 'As Far As I Know',\n",
       " 'FAQ': 'Frequently Asked Questions',\n",
       " 'TGIF': \"Thank God It's Friday\",\n",
       " 'FYA': 'For Your Action'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_words = {\n",
    "    'AFAIK':'As Far As I Know',\n",
    "    'AFK':'Away From Keyboard',\n",
    "    'ASAP':'As Soon As Possible'\n",
    "}\n",
    "\n",
    "\n",
    "{\n",
    "    \"FYI\": \"For Your Information\",\n",
    "    \"ASAP\": \"As Soon As Possible\",\n",
    "    \"BRB\": \"Be Right Back\",\n",
    "    \"BTW\": \"By The Way\",\n",
    "    \"OMG\": \"Oh My God\",\n",
    "    \"IMO\": \"In My Opinion\",\n",
    "    \"LOL\": \"Laugh Out Loud\",\n",
    "    \"TTYL\": \"Talk To You Later\",\n",
    "    \"GTG\": \"Got To Go\",\n",
    "    \"TTYT\": \"Talk To You Tomorrow\",\n",
    "    \"IDK\": \"I Don't Know\",\n",
    "    \"TMI\": \"Too Much Information\",\n",
    "    \"IMHO\": \"In My Humble Opinion\",\n",
    "    \"ICYMI\": \"In Case You Missed It\",\n",
    "    \"AFAIK\": \"As Far As I Know\",\n",
    "    \"BTW\": \"By The Way\",\n",
    "    \"FAQ\": \"Frequently Asked Questions\",\n",
    "    \"TGIF\": \"Thank God It's Friday\",\n",
    "    \"FYA\": \"For Your Action\",\n",
    "    \"ICYMI\": \"In Case You Missed It\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_conversion(text):\n",
    "    new_text = []\n",
    "    for w in text.split():\n",
    "        if w.upper() in chat_words:\n",
    "            new_text.append(chat_words[w.upper()])\n",
    "        else:\n",
    "            new_text.append(w)\n",
    "    return \" \".join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Do this work As Soon As Possible'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_conversion('Do this work ASAP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incorrect text handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in d:\\llm_ops\\tokenization-embeddings\\.venv\\lib\\site-packages (0.19.0)\n",
      "Requirement already satisfied: nltk>=3.9 in d:\\llm_ops\\tokenization-embeddings\\.venv\\lib\\site-packages (from textblob) (3.9.1)\n",
      "Requirement already satisfied: click in d:\\llm_ops\\tokenization-embeddings\\.venv\\lib\\site-packages (from nltk>=3.9->textblob) (8.1.8)\n",
      "Requirement already satisfied: joblib in d:\\llm_ops\\tokenization-embeddings\\.venv\\lib\\site-packages (from nltk>=3.9->textblob) (1.5.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\llm_ops\\tokenization-embeddings\\.venv\\lib\\site-packages (from nltk>=3.9->textblob) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in d:\\llm_ops\\tokenization-embeddings\\.venv\\lib\\site-packages (from nltk>=3.9->textblob) (4.67.1)\n",
      "Requirement already satisfied: colorama in d:\\llm_ops\\tokenization-embeddings\\.venv\\lib\\site-packages (from click->nltk>=3.9->textblob) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "certain conditions during several generations are modified in the same manner.\n"
     ]
    }
   ],
   "source": [
    "incorrect_text = 'ceertain conditionas duriing seveal ggenerations aree moodified in the saame maner.'\n",
    "\n",
    "# Try to use TextBlob if available\n",
    "try:\n",
    "    from textblob import TextBlob\n",
    "    textBlb = TextBlob(incorrect_text)\n",
    "    print(textBlb.correct().string)\n",
    "except ImportError:\n",
    "    print(\"TextBlob not available. Cannot perform spelling correction.\")\n",
    "    print(\"Original text: \", incorrect_text)\n",
    "    print(\"To install TextBlob: pip install textblob\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove emoji handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Loved the movie. It was '"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_emoji(\"Loved the movie. It was ðŸ˜˜ðŸ˜˜\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lmao '"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_emoji(\"Lmao ðŸ˜‚ðŸ˜‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python is :fire:\n"
     ]
    }
   ],
   "source": [
    "# Try to use emoji module if available\n",
    "try:\n",
    "    import emoji\n",
    "    print(emoji.demojize('Python is ðŸ”¥'))\n",
    "except ImportError:\n",
    "    print(\"Emoji module not available.\")\n",
    "    print(\"To install emoji: pip install emoji\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loved the movie. It was :face_blowing_a_kiss:\n"
     ]
    }
   ],
   "source": [
    "# Try to use emoji module if available\n",
    "try:\n",
    "    import emoji\n",
    "    print(emoji.demojize('Loved the movie. It was ðŸ˜˜'))\n",
    "except ImportError:\n",
    "    print(\"Emoji module not available.\")\n",
    "    print(\"To install emoji: pip install emoji\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Remove special characters and numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_chars(text):\n",
    "    \"\"\"Remove special characters and numbers\"\"\"\n",
    "    pattern = r'[^a-zA-z\\s]'\n",
    "    text = re.sub(pattern, '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply special character removal\n",
    "df['review'] = df['review'].apply(remove_special_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'basically theres a family where a little boy jake thinks theres a zombie in his closet  his parents are fighting all the timethis movie is slower than a soap opera and suddenly jake decides to become rambo and kill the zombieok first of all when youre going to make a film you must decide if its a thriller or a drama as a drama the movie is watchable parents are divorcing  arguing like in real life and then we have jake with his closet which totally ruins all the film i expected to see a boogeyman similar movie and instead i watched a drama with some meaningless thriller spots out of  just for the well playing parents  descent dialogs as for the shots with jake just ignore them'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the review after special character removal\n",
    "df['review'][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download stopwords if not already downloaded\n",
    "try:\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "except LookupError:\n",
    "    nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    \"\"\"Remove stopwords from text\"\"\"\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply stopword removal\n",
    "df['review'] = df['review'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'basically theres family little boy jake thinks theres zombie closet parents fighting timethis movie slower soap opera suddenly jake decides become rambo kill zombieok first youre going make film must decide thriller drama drama movie watchable parents divorcing arguing like real life jake closet totally ruins film expected see boogeyman similar movie instead watched drama meaningless thriller spots well playing parents descent dialogs shots jake ignore'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the review after stopword removal\n",
    "df['review'][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Initialize stemmer\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_words(text):\n",
    "    \"\"\"Apply stemming to words\"\"\"\n",
    "    words = text.split()\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]\n",
    "    return ' '.join(stemmed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply stemming\n",
    "df['review'] = df['review'].apply(stem_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'basic there famili littl boy jake think there zombi closet parent fight timethi movi slower soap opera suddenli jake decid becom rambo kill zombieok first your go make film must decid thriller drama drama movi watchabl parent divorc argu like real life jake closet total ruin film expect see boogeyman similar movi instead watch drama meaningless thriller spot well play parent descent dialog shot jake ignor'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the review after stemming\n",
    "df['review'][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Lemmatization (Alternative to Stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download WordNet if not already downloaded\n",
    "try:\n",
    "    nltk.data.find('corpora/wordnet')\n",
    "except LookupError:\n",
    "    nltk.download('wordnet')\n",
    "\n",
    "# Initialize lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_words(text):\n",
    "    \"\"\"Apply lemmatization to words\"\"\"\n",
    "    words = text.split()\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return ' '.join(lemmatized_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column for lemmatized text\n",
    "df['lemmatized_review'] = df['review'].apply(lemmatize_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'basic there famili littl boy jake think there zombi closet parent fight timethi movi slower soap opera suddenli jake decid becom rambo kill zombieok first your go make film must decid thriller drama drama movi watchabl parent divorc argu like real life jake closet total ruin film expect see boogeyman similar movi instead watch drama meaningless thriller spot well play parent descent dialog shot jake ignor'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the review after lemmatization\n",
    "df['lemmatized_review'][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Preprocessing Steps\n",
    "\n",
    "1. Loaded data directly using Kaggle API without downloading to disk\n",
    "2. Converted text to lowercase\n",
    "3. Removed HTML tags\n",
    "4. Removed special characters and numbers\n",
    "5. Removed stopwords\n",
    "6. Applied stemming\n",
    "7. Applied lemmatization (as an alternative to stemming)\n",
    "\n",
    "These preprocessing steps help clean the text data and prepare it for further analysis or modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>lemmatized_review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one review mention watch oz episod youll hook ...</td>\n",
       "      <td>one review mention watch oz episod youll hook ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonder littl product film techniqu unassum old...</td>\n",
       "      <td>wonder littl product film techniqu unassum old...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought wonder way spend time hot summer weeke...</td>\n",
       "      <td>thought wonder way spend time hot summer weeke...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basic there famili littl boy jake think there ...</td>\n",
       "      <td>basic there famili littl boy jake think there ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei love time money visual stun film...</td>\n",
       "      <td>petter mattei love time money visual stun film...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  \\\n",
       "0  one review mention watch oz episod youll hook ...   \n",
       "1  wonder littl product film techniqu unassum old...   \n",
       "2  thought wonder way spend time hot summer weeke...   \n",
       "3  basic there famili littl boy jake think there ...   \n",
       "4  petter mattei love time money visual stun film...   \n",
       "\n",
       "                                   lemmatized_review sentiment  \n",
       "0  one review mention watch oz episod youll hook ...  positive  \n",
       "1  wonder littl product film techniqu unassum old...  positive  \n",
       "2  thought wonder way spend time hot summer weeke...  positive  \n",
       "3  basic there famili littl boy jake think there ...  negative  \n",
       "4  petter mattei love time money visual stun film...  positive  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display final processed data\n",
    "df[['review', 'lemmatized_review', 'sentiment']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'delhi']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using split function\n",
    "# word tokenization\n",
    "sent1 = 'I am going to delhi'\n",
    "sent1.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I am going to delhi',\n",
       " ' I will stay there for 3 days',\n",
       " \" Let's hope the trip to be great\"]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sentence tokenization\n",
    "sent2 = 'I am going to delhi. I will stay there for 3 days. Let\\'s hope the trip to be great'\n",
    "sent2.split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'delhi!']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Problems with split function\n",
    "sent3 = 'I am going to delhi!'\n",
    "sent3.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Where do think I should go? I have 3 day holiday']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent4 = 'Where do think I should go? I have 3 day holiday'\n",
    "sent4.split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'delhi']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Regular expression\n",
    "import re\n",
    "sent3 = 'I am going to delhi!'\n",
    "tokens = re.findall(\"[\\w']+\", sent3)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Lorem Ipsum is simply dummy text of the printing and typesetting industry?\\nLorem Ipsum has been the industry's standard dummy text ever since the 1500s,\\nwhen an unknown printer took a galley of type and scrambled it to make a type specimen book.\"]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "text = \"\"\"Lorem Ipsum is simply dummy text of the printing and typesetting industry?\n",
    "Lorem Ipsum has been the industry's standard dummy text ever since the 1500s,\n",
    "when an unknown printer took a galley of type and scrambled it to make a type specimen book.\"\"\"\n",
    "sentences = re.compile('[.!?] ').split(text)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NLTK\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'visit', 'delhi', '!']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent1 = 'I am going to visit delhi!'\n",
    "word_tokenize(sent1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lorem Ipsum is simply dummy text of the printing and typesetting industry?',\n",
       " \"Lorem Ipsum has been the industry's standard dummy text ever since the 1500s,\\nwhen an unknown printer took a galley of type and scrambled it to make a type specimen book.\"]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"Lorem Ipsum is simply dummy text of the printing and typesetting industry?\n",
    "Lorem Ipsum has been the industry's standard dummy text ever since the 1500s,\n",
    "when an unknown printer took a galley of type and scrambled it to make a type specimen book.\"\"\"\n",
    "\n",
    "sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'have', 'a', 'Ph.D', 'in', 'A.I']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent5 = 'I have a Ph.D in A.I'\n",
    "sent6 = \"We're here to help! mail us at nks@gmail.com\"\n",
    "sent7 = 'A 5km ride cost $10.50'\n",
    "\n",
    "word_tokenize(sent5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We',\n",
       " \"'re\",\n",
       " 'here',\n",
       " 'to',\n",
       " 'help',\n",
       " '!',\n",
       " 'mail',\n",
       " 'us',\n",
       " 'at',\n",
       " 'nks',\n",
       " '@',\n",
       " 'gmail.com']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(sent6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', '5km', 'ride', 'cost', '$', '10.50']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(sent7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Package(s) not found: spacy\n"
     ]
    }
   ],
   "source": [
    "%pip show spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacyNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Using cached spacy-3.8.5-cp39-cp39-win_amd64.whl.metadata (28 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
      "  Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
      "  Using cached spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Using cached murmurhash-1.0.12-cp39-cp39-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Using cached cymem-2.0.11-cp39-cp39-win_amd64.whl.metadata (8.8 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Using cached preshed-3.0.9-cp39-cp39-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting thinc<8.4.0,>=8.3.4 (from spacy)\n",
      "  Using cached thinc-8.3.6-cp39-cp39-win_amd64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
      "  Using cached wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
      "  Using cached srsly-2.5.1-cp39-cp39-win_amd64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
      "  Using cached catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0 (from spacy)\n",
      "  Using cached weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typer<1.0.0,>=0.3.0 (from spacy)\n",
      "  Using cached typer-0.15.3-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in d:\\llm_ops\\tokenization-embeddings\\.venv\\lib\\site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in d:\\llm_ops\\tokenization-embeddings\\.venv\\lib\\site-packages (from spacy) (2.0.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in d:\\llm_ops\\tokenization-embeddings\\.venv\\lib\\site-packages (from spacy) (2.32.3)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 (from spacy)\n",
      "  Using cached pydantic-2.11.4-py3-none-any.whl.metadata (66 kB)\n",
      "Collecting jinja2 (from spacy)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: setuptools in d:\\llm_ops\\tokenization-embeddings\\.venv\\lib\\site-packages (from spacy) (58.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\llm_ops\\tokenization-embeddings\\.venv\\lib\\site-packages (from spacy) (25.0)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy)\n",
      "  Using cached langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Using cached language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
      "  Using cached pydantic_core-2.33.2-cp39-cp39-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in d:\\llm_ops\\tokenization-embeddings\\.venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.13.2)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
      "  Using cached typing_inspection-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\llm_ops\\tokenization-embeddings\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\llm_ops\\tokenization-embeddings\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\llm_ops\\tokenization-embeddings\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\llm_ops\\tokenization-embeddings\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.4.26)\n",
      "Collecting blis<1.4.0,>=1.3.0 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Using cached blis-1.3.0.tar.gz (2.5 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Using cached confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: colorama in d:\\llm_ops\\tokenization-embeddings\\.venv\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in d:\\llm_ops\\tokenization-embeddings\\.venv\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
      "  Using cached rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Using cached cloudpathlib-0.21.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting smart-open<8.0.0,>=5.2.1 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Using cached smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting wrapt (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Using cached wrapt-1.17.2-cp39-cp39-win_amd64.whl.metadata (6.5 kB)\n",
      "Collecting marisa-trie>=1.1.0 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Using cached marisa_trie-1.2.1-cp39-cp39-win_amd64.whl.metadata (9.3 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\llm_ops\\tokenization-embeddings\\.venv\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->spacy)\n",
      "  Using cached MarkupSafe-3.0.2-cp39-cp39-win_amd64.whl.metadata (4.1 kB)\n",
      "Using cached spacy-3.8.5-cp39-cp39-win_amd64.whl (12.3 MB)\n",
      "Using cached catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Using cached cymem-2.0.11-cp39-cp39-win_amd64.whl (39 kB)\n",
      "Using cached langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
      "Using cached murmurhash-1.0.12-cp39-cp39-win_amd64.whl (25 kB)\n",
      "Using cached preshed-3.0.9-cp39-cp39-win_amd64.whl (122 kB)\n",
      "Using cached pydantic-2.11.4-py3-none-any.whl (443 kB)\n",
      "Using cached pydantic_core-2.33.2-cp39-cp39-win_amd64.whl (2.0 MB)\n",
      "Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Using cached spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Using cached srsly-2.5.1-cp39-cp39-win_amd64.whl (633 kB)\n",
      "Using cached thinc-8.3.6-cp39-cp39-win_amd64.whl (1.8 MB)\n",
      "Using cached confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Using cached typer-0.15.3-py3-none-any.whl (45 kB)\n",
      "Using cached wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Using cached weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "Using cached cloudpathlib-0.21.0-py3-none-any.whl (52 kB)\n",
      "Using cached smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
      "Using cached marisa_trie-1.2.1-cp39-cp39-win_amd64.whl (152 kB)\n",
      "Using cached rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Using cached typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp39-cp39-win_amd64.whl (15 kB)\n",
      "Using cached wrapt-1.17.2-cp39-cp39-win_amd64.whl (38 kB)\n",
      "Building wheels for collected packages: blis\n",
      "  Building wheel for blis (pyproject.toml): started\n",
      "  Building wheel for blis (pyproject.toml): finished with status 'error'\n",
      "Failed to build blis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Ã— Building wheel for blis (pyproject.toml) did not run successfully.\n",
      "  â”‚ exit code: 1\n",
      "  â•°â”€> [36 lines of output]\n",
      "      BLIS_COMPILER? None\n",
      "      C:\\Windows\\Temp\\pip-build-env-3zo1er7r\\overlay\\Lib\\site-packages\\setuptools\\dist.py:761: SetuptoolsDeprecationWarning: License classifiers are deprecated.\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              Please consider removing the following classifiers in favor of a SPDX license expression:\n",
      "      \n",
      "              License :: OSI Approved :: BSD License\n",
      "      \n",
      "              See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        self._finalize_license_expression()\n",
      "      running bdist_wheel\n",
      "      running build\n",
      "      running build_py\n",
      "      creating build\\lib.win-amd64-cpython-39\\blis\n",
      "      copying blis\\about.py -> build\\lib.win-amd64-cpython-39\\blis\n",
      "      copying blis\\benchmark.py -> build\\lib.win-amd64-cpython-39\\blis\n",
      "      copying blis\\__init__.py -> build\\lib.win-amd64-cpython-39\\blis\n",
      "      creating build\\lib.win-amd64-cpython-39\\blis\\tests\n",
      "      copying blis\\tests\\common.py -> build\\lib.win-amd64-cpython-39\\blis\\tests\n",
      "      copying blis\\tests\\test_dotv.py -> build\\lib.win-amd64-cpython-39\\blis\\tests\n",
      "      copying blis\\tests\\test_gemm.py -> build\\lib.win-amd64-cpython-39\\blis\\tests\n",
      "      copying blis\\tests\\__init__.py -> build\\lib.win-amd64-cpython-39\\blis\\tests\n",
      "      copying blis\\cy.pyx -> build\\lib.win-amd64-cpython-39\\blis\n",
      "      copying blis\\py.pyx -> build\\lib.win-amd64-cpython-39\\blis\n",
      "      copying blis\\cy.pxd -> build\\lib.win-amd64-cpython-39\\blis\n",
      "      copying blis\\__init__.pxd -> build\\lib.win-amd64-cpython-39\\blis\n",
      "      running build_ext\n",
      "      Build options win32 msvc\n",
      "      BUILD ARCH: x86_64\n",
      "      {'ACLOCAL_PATH': 'C:\\\\Program Files\\\\Git\\\\mingw64\\\\share\\\\aclocal;C:\\\\Program Files\\\\Git\\\\usr\\\\share\\\\aclocal', 'ACTIONS_RUNNER_ACTION_ARCHIVE_CACHE': 'C:\\\\actionarchivecache\\\\', 'AGENT_BUILDDIRECTORY': 'D:\\\\a\\\\1', 'AGENT_CLOUDID': 'cc0b709a-2cb2-4727-8ec5-adb402963aba', 'AGENT_DISABLELOGPLUGIN_TESTFILEPUBLISHERPLUGIN': 'true', 'AGENT_DISABLELOGPLUGIN_TESTRESULTLOGPLUGIN': 'false', 'AGENT_ENABLE_PIPELINEARTIFACT_LARGE_CHUNK_SIZE': 'true', 'AGENT_HOMEDIRECTORY': 'C:\\\\agents\\\\3.248.0', 'AGENT_ID': '93', 'AGENT_ISSELFHOSTED': '0', 'AGENT_JOBNAME': 'JSONL Python39Windows', 'AGENT_JOBSTATUS': 'Succeeded', 'AGENT_LOGTOBLOBSTORAGESERVICE': 'true', 'AGENT_MACHINENAME': 'fv-az618-395', 'AGENT_NAME': 'Azure Pipelines 2', 'AGENT_OS': 'Windows_NT', 'AGENT_OSARCHITECTURE': 'X64', 'AGENT_READONLYVARIABLES': 'true', 'AGENT_RETAINDEFAULTENCODING': 'false', 'AGENT_ROOTDIRECTORY': 'D:\\\\a', 'AGENT_SERVEROMDIRECTORY': 'C:\\\\agents\\\\3.248.0\\\\externals\\\\vstsom', 'AGENT_TASKRESTRICTIONSENFORCEMENTMODE': 'Enabled', 'AGENT_TEMPDIRECTORY': 'D:\\\\a\\\\_temp', 'AGENT_TOOLSDIRECTORY': 'C:\\\\hostedtoolcache\\\\windows', 'AGENT_USEWORKSPACEID': 'true', 'AGENT_USE_FETCH_FILTER_IN_CHECKOUT_TASK': 'true', 'AGENT_VERSION': '4.248.0', 'AGENT_WORKFOLDER': 'D:\\\\a', 'ALLUSERSPROFILE': 'C:\\\\ProgramData', 'ANDROID_HOME': 'C:\\\\Android\\\\android-sdk', 'ANDROID_NDK': 'C:\\\\Android\\\\android-sdk\\\\ndk\\\\27.2.12479018', 'ANDROID_NDK_HOME': 'C:\\\\Android\\\\android-sdk\\\\ndk\\\\27.2.12479018', 'ANDROID_NDK_LATEST_HOME': 'C:\\\\Android\\\\android-sdk\\\\ndk\\\\27.2.12479018', 'ANDROID_NDK_ROOT': 'C:\\\\Android\\\\android-sdk\\\\ndk\\\\27.2.12479018', 'ANDROID_SDK_ROOT': 'C:\\\\Android\\\\android-sdk', 'ANT_HOME': 'C:\\\\ProgramData\\\\chocolatey\\\\lib\\\\ant\\\\tools\\\\apache-ant-1.10.14', 'APPDATA': 'C:\\\\Users\\\\VssAdministrator\\\\AppData\\\\Roaming', 'AZP_75787_ENABLE_COLLECT': 'true', 'AZP_75787_ENABLE_NEW_LOGIC': 'false', 'AZP_75787_ENABLE_NEW_LOGIC_LOG': 'false', 'AZP_75787_ENABLE_NEW_PH_LOGIC': 'true', 'AZP_AGENT_CHECK_FOR_TASK_DEPRECATION': 'true', 'AZP_AGENT_IGNORE_VSTSTASKLIB': 'true', 'AZP_AGENT_LOG_TASKNAME_IN_USERAGENT': 'true', 'AZP_AGENT_MOUNT_WORKSPACE': 'true', 'AZP_ENABLE_RESOURCE_MONITOR_DEBUG_OUTPUT': 'true', 'AZP_ENABLE_RESOURCE_UTILIZATION_WARNINGS': 'true', 'AZP_PS_ENABLE_INVOKE_PROCESS': 'true', 'AZURE_CONFIG_DIR': 'C:\\\\azureCli', 'AZURE_DEVOPS_CACHE_DIR': 'C:\\\\azureDevOpsCli\\\\cache', 'AZURE_EXTENSION_DIR': 'C:\\\\Program Files\\\\Common Files\\\\AzureCliExtensionDirectory', 'AZURE_HTTP_USER_AGENT': 'VSTS_116cc368-5c0c-4eb4-bb44-7f3fa5bdce14_build_6_0', 'AZ_DEVOPS_GLOBAL_CONFIG_DIR': 'C:\\\\azureDevOpsCli', 'BUILD_ARTIFACTSTAGINGDIRECTORY': 'D:\\\\a\\\\1\\\\a', 'BUILD_BINARIESDIRECTORY': 'D:\\\\a\\\\1\\\\b', 'BUILD_BUILDID': '27184', 'BUILD_BUILDNUMBER': '20250110.10', 'BUILD_BUILDURI': 'vstfs:///Build/Build/27184', 'BUILD_CONTAINERID': '29126447', 'BUILD_DEFINITIONFOLDERPATH': '\\\\', 'BUILD_DEFINITIONNAME': 'explosion.cython-blis', 'BUILD_DEFINITIONVERSION': '1', 'BUILD_QUEUEDBY': 'Microsoft.VisualStudio.Services.TFS', 'BUILD_QUEUEDBYID': '00000002-0000-8888-8000-000000000000', 'BUILD_REASON': 'BatchedCI', 'BUILD_REPOSITORY_CLEAN': 'False', 'BUILD_REPOSITORY_GIT_SUBMODULECHECKOUT': 'False', 'BUILD_REPOSITORY_ID': 'explosion/cython-blis', 'BUILD_REPOSITORY_LOCALPATH': 'D:\\\\a\\\\1\\\\s', 'BUILD_REPOSITORY_NAME': 'explosion/cython-blis', 'BUILD_REPOSITORY_PROVIDER': 'GitHub', 'BUILD_REPOSITORY_URI': 'https://github.com/explosion/cython-blis', 'BUILD_REQUESTEDFOR': 'Microsoft.VisualStudio.Services.TFS', 'BUILD_REQUESTEDFOREMAIL': '', 'BUILD_REQUESTEDFORID': '00000002-0000-8888-8000-000000000000', 'BUILD_SOURCEBRANCH': 'refs/heads/v0.8.x', 'BUILD_SOURCEBRANCHNAME': 'v0.8.x', 'BUILD_SOURCESDIRECTORY': 'D:\\\\a\\\\1\\\\s', 'BUILD_SOURCEVERSION': '2cb93566856d208bc951d5847171583d6379406a', 'BUILD_SOURCEVERSIONAUTHOR': 'honnibal', 'BUILD_SOURCEVERSIONMESSAGE': 'Edit ap', 'BUILD_STAGINGDIRECTORY': 'D:\\\\a\\\\1\\\\a', 'CABAL_DIR': 'C:\\\\cabal', 'COBERTURA_HOME': 'C:\\\\cobertura-2.1.1', 'COMMONPROGRAMFILES': 'C:\\\\Program Files\\\\Common Files', 'COMMON_TESTRESULTSDIRECTORY': 'D:\\\\a\\\\1\\\\TestResults', 'COMPUTERNAME': 'fv-az618-395', 'COMSPEC': 'C:\\\\Windows\\\\system32\\\\cmd.exe', 'CONDA': 'C:\\\\Miniconda', 'CONFIG_SITE': 'C:/Program Files/Git/etc/config.site', 'COPYFILESOVERSSHV0_USE_QUEUE': 'true', 'CHOCOLATEYINSTALL': 'C:\\\\ProgramData\\\\chocolatey', 'CHROMEWEBDRIVER': 'C:\\\\SeleniumWebDrivers\\\\ChromeDriver', 'COMMONPROGRAMFILES(X86)': 'C:\\\\Program Files (x86)\\\\Common Files', 'COMMONPROGRAMW6432': 'C:\\\\Program Files\\\\Common Files', 'DISPLAY': 'needs-to-be-defined', 'DISTRIBUTEDTASK_AGENT_ADDFORCECREDENTIALSTOGITCHECKOUT': 'True', 'DISTRIBUTEDTASK_AGENT_AGENTENABLEPIPELINEARTIFACTLARGECHUNKSIZE': 'True', 'DISTRIBUTEDTASK_AGENT_CHECKIFTASKNODERUNNERISDEPRECATED246': 'True', 'DISTRIBUTEDTASK_AGENT_CONTINUEAFTERCANCELPROCESSTREEKILLATTEMPT': 'True', 'DISTRIBUTEDTASK_AGENT_DOCKERACTIONRETRIES': 'True', 'DISTRIBUTEDTASK_AGENT_ENABLEADDITIONALMASKINGREGEXES': 'True', 'DISTRIBUTEDTASK_AGENT_ENABLEISSUESOURCEVALIDATION': 'True', 'DISTRIBUTEDTASK_AGENT_ENABLERESOURCEMONITORDEBUGOUTPUT': 'True', 'DISTRIBUTEDTASK_AGENT_ENABLERESOURCEUTILIZATIONWARNINGS': 'True', 'DISTRIBUTEDTASK_AGENT_FAILDEPRECATEDBUILDTASK': 'True', 'DISTRIBUTEDTASK_AGENT_FAILDEPRECATEDTASK': 'True', 'DISTRIBUTEDTASK_AGENT_FAILJOBWHENAGENTDIES': 'True', 'DISTRIBUTEDTASK_AGENT_FIXPOSSIBLEGITOUTOFMEMORYPROBLEM': 'False', 'DISTRIBUTEDTASK_AGENT_FORCEUPDATETOLATEST2VERSION': 'False', 'DISTRIBUTEDTASK_AGENT_IGNOREVSTSTASKLIB': 'True', 'DISTRIBUTEDTASK_AGENT_LOGTASKNAMEINUSERAGENT': 'True', 'DISTRIBUTEDTASK_AGENT_LOGTOBLOBSTORAGESERVICE': 'True', 'DISTRIBUTEDTASK_AGENT_MOUNTWORKSPACE': 'True', 'DISTRIBUTEDTASK_AGENT_READONLYVARIABLES': 'True', 'DISTRIBUTEDTASK_AGENT_ROSETTA2WARNING': 'True', 'DISTRIBUTEDTASK_AGENT_USEDOCKERCOMPOSEV2COMPATIBLEMODE': 'False', 'DISTRIBUTEDTASK_AGENT_USEFETCHFILTERINCHECKOUTTASK': 'True', 'DISTRIBUTEDTASK_AGENT_USEGITLONGPATHS': 'True', 'DISTRIBUTEDTASK_AGENT_USELATESTGITVERSION': 'True', 'DISTRIBUTEDTASK_AGENT_USEMSALLIBRARY': 'True', 'DISTRIBUTEDTASK_AGENT_USENEWNODEHANDLERTELEMETRY': 'True', 'DISTRIBUTEDTASK_AGENT_USENODE20TOSTARTCONTAINER': 'True', 'DISTRIBUTEDTASK_AGENT_USEWORKSPACEID': 'True', 'DISTRIBUTEDTASK_TASKS_COPYFILESOVERSSHV0USEQUEUE': 'True', 'DISTRIBUTEDTASK_TASKS_NODE_SKIPDEBUGLOGSWHENDEBUGMODEOFF': 'True', 'DISTRIBUTEDTASK_TASKS_RETIREAZURERMPOWERSHELLMODULE': 'True', 'DOTNET_MULTILEVEL_LOOKUP': '0', 'DOTNET_NOLOGO': '1', 'DOTNET_SKIP_FIRST_TIME_EXPERIENCE': '1', 'DRIVERDATA': 'C:\\\\Windows\\\\System32\\\\Drivers\\\\DriverData', 'ENABLE_ISSUE_SOURCE_VALIDATION': 'true', 'EXEPATH': 'C:\\\\Program Files\\\\Git\\\\bin', 'EDGEWEBDRIVER': 'C:\\\\SeleniumWebDrivers\\\\EdgeDriver', 'FAIL_DEPRECATED_BUILD_TASK': 'true', 'FAIL_DEPRECATED_TASK': 'true', 'FAIL_JOB_WHEN_AGENT_DIES': 'true', 'GCM_INTERACTIVE': 'Never', 'GHCUP_INSTALL_BASE_PREFIX': 'C:\\\\', 'GHCUP_MSYS2': 'C:\\\\msys64', 'GIT_TERMINAL_PROMPT': '0', 'GOROOT_1_20_X64': 'C:\\\\hostedtoolcache\\\\windows\\\\go\\\\1.20.14\\\\x64', 'GOROOT_1_21_X64': 'C:\\\\hostedtoolcache\\\\windows\\\\go\\\\1.21.13\\\\x64', 'GOROOT_1_22_X64': 'C:\\\\hostedtoolcache\\\\windows\\\\go\\\\1.22.10\\\\x64', 'GOROOT_1_23_X64': 'C:\\\\hostedtoolcache\\\\windows\\\\go\\\\1.23.4\\\\x64', 'GRADLE_HOME': 'C:\\\\ProgramData\\\\chocolatey\\\\lib\\\\gradle\\\\tools\\\\gradle-8.12', 'GECKOWEBDRIVER': 'C:\\\\SeleniumWebDrivers\\\\GeckoDriver', 'HOME': 'C:\\\\Users\\\\VssAdministrator', 'HOMEDRIVE': 'C:', 'HOMEPATH': '\\\\Users\\\\VssAdministrator', 'HOSTNAME': 'fv-az618-395', 'IEWEBDRIVER': 'C:\\\\SeleniumWebDrivers\\\\IEDriver', 'IMAGENAME': 'windows-latest', 'INFOPATH': 'C:\\\\Program Files\\\\Git\\\\mingw64\\\\local\\\\info;C:\\\\Program Files\\\\Git\\\\mingw64\\\\share\\\\info;C:\\\\Program Files\\\\Git\\\\usr\\\\local\\\\info;C:\\\\Program Files\\\\Git\\\\usr\\\\share\\\\info;C:\\\\Program Files\\\\Git\\\\usr\\\\info;C:\\\\Program Files\\\\Git\\\\share\\\\info', 'IMAGEOS': 'win22', 'IMAGEVERSION': '20250105.1.0', 'JAVA_HOME': 'C:\\\\hostedtoolcache\\\\windows\\\\Java_Temurin-Hotspot_jdk\\\\8.0.432-6\\\\x64', 'JAVA_HOME_11_X64': 'C:\\\\hostedtoolcache\\\\windows\\\\Java_Temurin-Hotspot_jdk\\\\11.0.25-9\\\\x64', 'JAVA_HOME_17_X64': 'C:\\\\hostedtoolcache\\\\windows\\\\Java_Temurin-Hotspot_jdk\\\\17.0.13-11\\\\x64', 'JAVA_HOME_21_X64': 'C:\\\\hostedtoolcache\\\\windows\\\\Java_Temurin-Hotspot_jdk\\\\21.0.5-11.0\\\\x64', 'JAVA_HOME_8_X64': 'C:\\\\hostedtoolcache\\\\windows\\\\Java_Temurin-Hotspot_jdk\\\\8.0.432-6\\\\x64', 'LANG': 'en_US.UTF-8', 'LOCALAPPDATA': 'C:\\\\Users\\\\VssAdministrator\\\\AppData\\\\Local', 'LOGONSERVER': '\\\\\\\\fv-az618-395', 'M2': 'C:\\\\ProgramData\\\\chocolatey\\\\lib\\\\maven\\\\apache-maven-3.8.7\\\\bin', 'M2_REPO': 'C:\\\\ProgramData\\\\m2', 'MANPATH': 'C:\\\\Program Files\\\\Git\\\\mingw64\\\\local\\\\man;C:\\\\Program Files\\\\Git\\\\mingw64\\\\share\\\\man;C:\\\\Program Files\\\\Git\\\\usr\\\\local\\\\man;C:\\\\Program Files\\\\Git\\\\usr\\\\share\\\\man;C:\\\\Program Files\\\\Git\\\\usr\\\\man;C:\\\\Program Files\\\\Git\\\\share\\\\man', 'MAVEN_OPTS': '-Xms256m', 'MINGW_CHOST': 'x86_64-w64-mingw32', 'MINGW_PACKAGE_PREFIX': 'mingw-w64-x86_64', 'MINGW_PREFIX': 'C:/Program Files/Git/mingw64', 'MSDEPLOY_HTTP_USER_AGENT': 'VSTS_116cc368-5c0c-4eb4-bb44-7f3fa5bdce14_build_6_0', 'MSYSTEM': 'MINGW64', 'MSYSTEM_CARCH': 'x86_64', 'MSYSTEM_CHOST': 'x86_64-w64-mingw32', 'MSYSTEM_PREFIX': 'C:/Program Files/Git/mingw64', 'NUMBER_OF_PROCESSORS': '2', 'OLDPWD': 'D:/a/1/s', 'ORIGINAL_PATH': 'C:\\\\Program Files\\\\Git\\\\mingw64\\\\bin;C:\\\\Program Files\\\\Git\\\\usr\\\\bin;C:\\\\Users\\\\VssAdministrator\\\\bin;C:\\\\Users\\\\VssAdministrator\\\\AppData\\\\Roaming\\\\Python\\\\Python39\\\\Scripts;C:\\\\hostedtoolcache\\\\windows\\\\Python\\\\3.9.13\\\\x64\\\\Scripts;C:\\\\hostedtoolcache\\\\windows\\\\Python\\\\3.9.13\\\\x64;C:\\\\agents\\\\3.248.0\\\\externals\\\\git\\\\cmd;C:\\\\agents\\\\3.248.0\\\\externals\\\\git\\\\mingw64\\\\bin;C:\\\\Program Files\\\\MongoDB\\\\Server\\\\5.0\\\\bin;C:\\\\aliyun-cli;C:\\\\vcpkg;C:\\\\Program Files (x86)\\\\NSIS;C:\\\\tools\\\\zstd;C:\\\\Program Files\\\\Mercurial;C:\\\\hostedtoolcache\\\\windows\\\\stack\\\\3.3.1\\\\x64;C:\\\\cabal\\\\bin;C:\\\\ghcup\\\\bin;C:\\\\mingw64\\\\bin;C:\\\\Program Files\\\\dotnet;C:\\\\Program Files\\\\MySQL\\\\MySQL Server 8.0\\\\bin;C:\\\\Program Files\\\\R\\\\R-4.4.2\\\\bin\\\\x64;C:\\\\SeleniumWebDrivers\\\\GeckoDriver;C:\\\\SeleniumWebDrivers\\\\EdgeDriver;C:\\\\SeleniumWebDrivers\\\\ChromeDriver;C:\\\\Program Files (x86)\\\\sbt\\\\bin;C:\\\\Program Files (x86)\\\\GitHub CLI;C:\\\\Program Files\\\\Git\\\\usr\\\\bin;C:\\\\Program Files (x86)\\\\pipx_bin;C:\\\\npm\\\\prefix;C:\\\\hostedtoolcache\\\\windows\\\\go\\\\1.21.13\\\\x64\\\\bin;C:\\\\hostedtoolcache\\\\windows\\\\Python\\\\3.9.13\\\\x64\\\\Scripts;C:\\\\hostedtoolcache\\\\windows\\\\Python\\\\3.9.13\\\\x64;C:\\\\hostedtoolcache\\\\windows\\\\Ruby\\\\3.0.7\\\\x64\\\\bin;C:\\\\Program Files\\\\OpenSSL\\\\bin;C:\\\\tools\\\\kotlinc\\\\bin;C:\\\\hostedtoolcache\\\\windows\\\\Java_Temurin-Hotspot_jdk\\\\8.0.432-6\\\\x64\\\\bin;C:\\\\Program Files\\\\ImageMagick-7.1.1-Q16-HDRI;C:\\\\Program Files\\\\Microsoft SDKs\\\\Azure\\\\CLI2\\\\wbin;C:\\\\ProgramData\\\\kind;C:\\\\ProgramData\\\\Chocolatey\\\\bin;C:\\\\Windows\\\\system32;C:\\\\Windows;C:\\\\Windows\\\\System32\\\\Wbem;C:\\\\Windows\\\\System32\\\\WindowsPowerShell\\\\v1.0;C:\\\\Windows\\\\System32\\\\OpenSSH;C:\\\\Program Files\\\\dotnet;C:\\\\Program Files\\\\PowerShell\\\\7;C:\\\\Program Files\\\\Microsoft\\\\Web Platform Installer;C:\\\\Program Files\\\\TortoiseSVN\\\\bin;C:\\\\Program Files\\\\Microsoft SQL Server\\\\Client SDK\\\\ODBC\\\\170\\\\Tools\\\\Binn;C:\\\\Program Files\\\\Microsoft SQL Server\\\\150\\\\Tools\\\\Binn;C:\\\\Program Files (x86)\\\\Windows Kits\\\\10\\\\Windows Performance Toolkit;C:\\\\Program Files (x86)\\\\WiX Toolset v3.14\\\\bin;C:\\\\Program Files\\\\Microsoft SQL Server\\\\130\\\\DTS\\\\Binn;C:\\\\Program Files\\\\Microsoft SQL Server\\\\140\\\\DTS\\\\Binn;C:\\\\Program Files\\\\Microsoft SQL Server\\\\150\\\\DTS\\\\Binn;C:\\\\Program Files\\\\Microsoft SQL Server\\\\160\\\\DTS\\\\Binn;C:\\\\Strawberry\\\\c\\\\bin;C:\\\\Strawberry\\\\perl\\\\site\\\\bin;C:\\\\Strawberry\\\\perl\\\\bin;C:\\\\ProgramData\\\\chocolatey\\\\lib\\\\pulumi\\\\tools\\\\Pulumi\\\\bin;C:\\\\Program Files\\\\CMake\\\\bin;C:\\\\ProgramData\\\\chocolatey\\\\lib\\\\maven\\\\apache-maven-3.8.7\\\\bin;C:\\\\Program Files\\\\Microsoft Service Fabric\\\\bin\\\\Fabric\\\\Fabric.Code;C:\\\\Program Files\\\\Microsoft SDKs\\\\Service Fabric\\\\Tools\\\\ServiceFabricLocalClusterManager;C:\\\\Program Files\\\\nodejs;C:\\\\Program Files\\\\Git\\\\cmd;C:\\\\Program Files\\\\Git\\\\mingw64\\\\bin;C:\\\\Program Files\\\\Git\\\\usr\\\\bin;C:\\\\Program Files\\\\GitHub CLI;C:\\\\tools\\\\php;C:\\\\Program Files (x86)\\\\sbt\\\\bin;C:\\\\Program Files\\\\Amazon\\\\AWSCLIV2;C:\\\\Program Files\\\\Amazon\\\\SessionManagerPlugin\\\\bin;C:\\\\Program Files\\\\Amazon\\\\AWSSAMCLI\\\\bin;C:\\\\Program Files\\\\Microsoft SQL Server\\\\130\\\\Tools\\\\Binn;C:\\\\Program Files\\\\LLVM\\\\bin;C:\\\\Users\\\\VssAdministrator\\\\.dotnet\\\\tools;C:\\\\Users\\\\VssAdministrator\\\\.cargo\\\\bin;C:\\\\Users\\\\VssAdministrator\\\\AppData\\\\Local\\\\Microsoft\\\\WindowsApps', 'ORIGINAL_TEMP': 'C:/Users/VSSADM~1/AppData/Local/Temp', 'ORIGINAL_TMP': 'C:/Users/VSSADM~1/AppData/Local/Temp', 'OS': 'windows', 'PATH': 'C:\\\\Users\\\\VssAdministrator\\\\bin;C:\\\\Program Files\\\\Git\\\\mingw64\\\\bin;C:\\\\Program Files\\\\Git\\\\usr\\\\local\\\\bin;C:\\\\Program Files\\\\Git\\\\usr\\\\bin;C:\\\\Program Files\\\\Git\\\\usr\\\\bin;C:\\\\Program Files\\\\Git\\\\mingw64\\\\bin;C:\\\\Program Files\\\\Git\\\\usr\\\\bin;C:\\\\Users\\\\VssAdministrator\\\\bin;C:\\\\Users\\\\VssAdministrator\\\\AppData\\\\Roaming\\\\Python\\\\Python39\\\\Scripts;C:\\\\hostedtoolcache\\\\windows\\\\Python\\\\3.9.13\\\\x64\\\\Scripts;C:\\\\hostedtoolcache\\\\windows\\\\Python\\\\3.9.13\\\\x64;C:\\\\agents\\\\3.248.0\\\\externals\\\\git\\\\cmd;C:\\\\agents\\\\3.248.0\\\\externals\\\\git\\\\mingw64\\\\bin;C:\\\\Program Files\\\\MongoDB\\\\Server\\\\5.0\\\\bin;C:\\\\aliyun-cli;C:\\\\vcpkg;C:\\\\Program Files (x86)\\\\NSIS;C:\\\\tools\\\\zstd;C:\\\\Program Files\\\\Mercurial;C:\\\\hostedtoolcache\\\\windows\\\\stack\\\\3.3.1\\\\x64;C:\\\\cabal\\\\bin;C:\\\\ghcup\\\\bin;C:\\\\mingw64\\\\bin;C:\\\\Program Files\\\\dotnet;C:\\\\Program Files\\\\MySQL\\\\MySQL Server 8.0\\\\bin;C:\\\\Program Files\\\\R\\\\R-4.4.2\\\\bin\\\\x64;C:\\\\SeleniumWebDrivers\\\\GeckoDriver;C:\\\\SeleniumWebDrivers\\\\EdgeDriver;C:\\\\SeleniumWebDrivers\\\\ChromeDriver;C:\\\\Program Files (x86)\\\\sbt\\\\bin;C:\\\\Program Files (x86)\\\\GitHub CLI;C:\\\\Program Files\\\\Git\\\\usr\\\\bin;C:\\\\Program Files (x86)\\\\pipx_bin;C:\\\\npm\\\\prefix;C:\\\\hostedtoolcache\\\\windows\\\\go\\\\1.21.13\\\\x64\\\\bin;C:\\\\hostedtoolcache\\\\windows\\\\Python\\\\3.9.13\\\\x64\\\\Scripts;C:\\\\hostedtoolcache\\\\windows\\\\Python\\\\3.9.13\\\\x64;C:\\\\hostedtoolcache\\\\windows\\\\Ruby\\\\3.0.7\\\\x64\\\\bin;C:\\\\Program Files\\\\OpenSSL\\\\bin;C:\\\\tools\\\\kotlinc\\\\bin;C:\\\\hostedtoolcache\\\\windows\\\\Java_Temurin-Hotspot_jdk\\\\8.0.432-6\\\\x64\\\\bin;C:\\\\Program Files\\\\ImageMagick-7.1.1-Q16-HDRI;C:\\\\Program Files\\\\Microsoft SDKs\\\\Azure\\\\CLI2\\\\wbin;C:\\\\ProgramData\\\\kind;C:\\\\ProgramData\\\\Chocolatey\\\\bin;C:\\\\Windows\\\\system32;C:\\\\Windows;C:\\\\Windows\\\\System32\\\\Wbem;C:\\\\Windows\\\\System32\\\\WindowsPowerShell\\\\v1.0;C:\\\\Windows\\\\System32\\\\OpenSSH;C:\\\\Program Files\\\\dotnet;C:\\\\Program Files\\\\PowerShell\\\\7;C:\\\\Program Files\\\\Microsoft\\\\Web Platform Installer;C:\\\\Program Files\\\\TortoiseSVN\\\\bin;C:\\\\Program Files\\\\Microsoft SQL Server\\\\Client SDK\\\\ODBC\\\\170\\\\Tools\\\\Binn;C:\\\\Program Files\\\\Microsoft SQL Server\\\\150\\\\Tools\\\\Binn;C:\\\\Program Files (x86)\\\\Windows Kits\\\\10\\\\Windows Performance Toolkit;C:\\\\Program Files (x86)\\\\WiX Toolset v3.14\\\\bin;C:\\\\Program Files\\\\Microsoft SQL Server\\\\130\\\\DTS\\\\Binn;C:\\\\Program Files\\\\Microsoft SQL Server\\\\140\\\\DTS\\\\Binn;C:\\\\Program Files\\\\Microsoft SQL Server\\\\150\\\\DTS\\\\Binn;C:\\\\Program Files\\\\Microsoft SQL Server\\\\160\\\\DTS\\\\Binn;C:\\\\Strawberry\\\\c\\\\bin;C:\\\\Strawberry\\\\perl\\\\site\\\\bin;C:\\\\Strawberry\\\\perl\\\\bin;C:\\\\ProgramData\\\\chocolatey\\\\lib\\\\pulumi\\\\tools\\\\Pulumi\\\\bin;C:\\\\Program Files\\\\CMake\\\\bin;C:\\\\ProgramData\\\\chocolatey\\\\lib\\\\maven\\\\apache-maven-3.8.7\\\\bin;C:\\\\Program Files\\\\Microsoft Service Fabric\\\\bin\\\\Fabric\\\\Fabric.Code;C:\\\\Program Files\\\\Microsoft SDKs\\\\Service Fabric\\\\Tools\\\\ServiceFabricLocalClusterManager;C:\\\\Program Files\\\\nodejs;C:\\\\Program Files\\\\Git\\\\cmd;C:\\\\Program Files\\\\Git\\\\mingw64\\\\bin;C:\\\\Program Files\\\\Git\\\\usr\\\\bin;C:\\\\Program Files\\\\GitHub CLI;C:\\\\tools\\\\php;C:\\\\Program Files (x86)\\\\sbt\\\\bin;C:\\\\Program Files\\\\Amazon\\\\AWSCLIV2;C:\\\\Program Files\\\\Amazon\\\\SessionManagerPlugin\\\\bin;C:\\\\Program Files\\\\Amazon\\\\AWSSAMCLI\\\\bin;C:\\\\Program Files\\\\Microsoft SQL Server\\\\130\\\\Tools\\\\Binn;C:\\\\Program Files\\\\LLVM\\\\bin;C:\\\\Users\\\\VssAdministrator\\\\.dotnet\\\\tools;C:\\\\Users\\\\VssAdministrator\\\\.cargo\\\\bin;C:\\\\Users\\\\VssAdministrator\\\\AppData\\\\Local\\\\Microsoft\\\\WindowsApps;C:\\\\Program Files\\\\Git\\\\usr\\\\bin\\\\vendor_perl;C:\\\\Program Files\\\\Git\\\\usr\\\\bin\\\\core_perl', 'PATHEXT': '.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC;.CPL', 'PGBIN': 'C:\\\\Program Files\\\\PostgreSQL\\\\14\\\\bin', 'PGDATA': 'C:\\\\Program Files\\\\PostgreSQL\\\\14\\\\data', 'PGPASSWORD': 'root', 'PGROOT': 'C:\\\\Program Files\\\\PostgreSQL\\\\14', 'PGUSER': 'postgres', 'PHPROOT': 'c:\\\\tools\\\\php', 'PIPELINE_REPOSITORY_NAME': 'explosion/cython-blis', 'PIPELINE_WORKSPACE': 'D:\\\\a\\\\1', 'PIPX_BIN_DIR': 'C:\\\\Program Files (x86)\\\\pipx_bin', 'PIPX_HOME': 'C:\\\\Program Files (x86)\\\\pipx', 'PKG_CONFIG_PATH': 'C:\\\\Program Files\\\\Git\\\\mingw64\\\\lib\\\\pkgconfig;C:\\\\Program Files\\\\Git\\\\mingw64\\\\share\\\\pkgconfig', 'PKG_CONFIG_SYSTEM_INCLUDE_PATH': 'C:/Program Files/Git/mingw64/include', 'PKG_CONFIG_SYSTEM_LIBRARY_PATH': 'C:/Program Files/Git/mingw64/lib', 'PLINK_PROTOCOL': 'ssh', 'POWERSHELL_DISTRIBUTION_CHANNEL': 'Azure-DevOps-win22', 'POWERSHELL_UPDATECHECK': 'Off', 'PROCESSOR_ARCHITECTURE': 'AMD64', 'PROCESSOR_IDENTIFIER': 'Intel64 Family 6 Model 79 Stepping 1, GenuineIntel', 'PROCESSOR_LEVEL': '6', 'PROCESSOR_REVISION': '4f01', 'PROGRAMFILES': 'C:\\\\Program Files', 'PROMPT': '$P$G', 'PSEXECUTIONPOLICYPREFERENCE': 'Unrestricted', 'PSMODULEANALYSISCACHEPATH': 'C:\\\\PSModuleAnalysisCachePath\\\\ModuleAnalysisCache', 'PSMODULEPATH': 'C:\\\\Users\\\\VssAdministrator\\\\Documents\\\\WindowsPowerShell\\\\Modules;C:\\\\\\\\Modules\\\\azurerm_2.1.0;C:\\\\\\\\Modules\\\\azure_2.1.0;C:\\\\Users\\\\packer\\\\Documents\\\\WindowsPowerShell\\\\Modules;C:\\\\Program Files\\\\WindowsPowerShell\\\\Modules;C:\\\\Windows\\\\system32\\\\WindowsPowerShell\\\\v1.0\\\\Modules;C:\\\\Program Files\\\\Microsoft SQL Server\\\\130\\\\Tools\\\\PowerShell\\\\Modules\\\\', 'PUBLIC': 'C:\\\\Users\\\\Public', 'PWD': 'D:/a/1/s/flame-blis', 'PYTHON_VERSION': '3.9', 'PROGRAMDATA': 'C:\\\\ProgramData', 'PROGRAMFILES(X86)': 'C:\\\\Program Files (x86)', 'PROGRAMW6432': 'C:\\\\Program Files', 'RESOURCES_TRIGGERINGALIAS': '', 'RESOURCES_TRIGGERINGCATEGORY': '', 'RETIRE_AZURERM_POWERSHELL_MODULE': 'true', 'ROSETTA2_WARNING': 'true', 'RTOOLS44_HOME': 'C:\\\\rtools44', 'RUNNER_TOOLSDIRECTORY': 'C:\\\\hostedtoolcache\\\\windows', 'RUNNER_TOOL_CACHE': 'C:\\\\hostedtoolcache\\\\windows', 'SBT_HOME': 'C:\\\\Program Files (x86)\\\\sbt\\\\', 'SELENIUM_JAR_PATH': 'C:\\\\selenium\\\\selenium-server.jar', 'SHELL': 'C:\\\\Program Files\\\\Git\\\\usr\\\\bin\\\\bash.exe', 'SHLVL': '1', 'SSH_ASKPASS': 'C:/Program Files/Git/mingw64/bin/git-askpass.exe', 'STATS_BLT': 'true', 'STATS_D': 'true', 'STATS_D_D': 'true', 'STATS_D_TC': 'true', 'STATS_EXT': 'true', 'STATS_EXTP': 'https://provjobdprod.z13.web.core.windows.net/settings/provjobdsettings-latest/provjobd.data', 'STATS_PIP': 'false', 'STATS_RDCL': 'true', 'STATS_TRP': 'true', 'STATS_UE': 'true', 'STATS_V3PS': 'true', 'STATS_VMD': 'true', 'STATS_VMFE': 'true', 'SYSTEM': 'build', 'SYSTEMDRIVE': 'C:', 'SYSTEMROOT': 'C:\\\\Windows', 'SYSTEM_ARTIFACTSDIRECTORY': 'D:\\\\a\\\\1\\\\a', 'SYSTEM_COLLECTIONID': '116cc368-5c0c-4eb4-bb44-7f3fa5bdce14', 'SYSTEM_COLLECTIONURI': 'https://dev.azure.com/explosion-ai/', 'SYSTEM_CULTURE': 'en-US', 'SYSTEM_DEBUG': 'false', 'SYSTEM_DEFAULTWORKINGDIRECTORY': 'D:\\\\a\\\\1\\\\s', 'SYSTEM_DEFINITIONID': '6', 'SYSTEM_DEFINITIONNAME': 'explosion.cython-blis', 'SYSTEM_ENABLEACCESSTOKEN': 'SecretVariable', 'SYSTEM_HOSTTYPE': 'build', 'SYSTEM_ISAZUREVM': '1', 'SYSTEM_ISDOCKERCONTAINER': '0', 'SYSTEM_ISSCHEDULED': 'False', 'SYSTEM_JOBATTEMPT': '1', 'SYSTEM_JOBDISPLAYNAME': 'JSONL Python39Windows', 'SYSTEM_JOBID': 'b59b5e76-e04f-54cc-443e-737e71f5428d', 'SYSTEM_JOBIDENTIFIER': 'JSONL.Python39Windows', 'SYSTEM_JOBNAME': 'Python39Windows', 'SYSTEM_JOBPARALLELISMTAG': 'Public', 'SYSTEM_JOBPOSITIONINPHASE': '2', 'SYSTEM_JOBTIMEOUT': '60', 'SYSTEM_OIDCREQUESTURI': 'https://dev.azure.com/explosion-ai/5c6613e9-6ccf-48bd-81de-dbc3b0a6f957/_apis/distributedtask/hubs/build/plans/5471f6a2-5d2d-4ea1-bf2f-6682941b17de/jobs/b59b5e76-e04f-54cc-443e-737e71f5428d/oidctoken', 'SYSTEM_PARALLELEXECUTIONTYPE': 'MultiConfiguration', 'SYSTEM_PHASEATTEMPT': '1', 'SYSTEM_PHASEDISPLAYNAME': 'JSONL', 'SYSTEM_PHASEID': 'ecb95708-c2a5-5456-f379-96cd8090c2a6', 'SYSTEM_PHASENAME': 'JSONL', 'SYSTEM_PIPELINESTARTTIME': '2025-01-10 17:44:05+00:00', 'SYSTEM_PLANID': '5471f6a2-5d2d-4ea1-bf2f-6682941b17de', 'SYSTEM_POSTLINESSPEED': '10000', 'SYSTEM_PULLREQUEST_ISFORK': 'False', 'SYSTEM_SERVERTYPE': 'Hosted', 'SYSTEM_STAGEATTEMPT': '1', 'SYSTEM_STAGEDISPLAYNAME': '__default', 'SYSTEM_STAGEID': '96ac2280-8cb4-5df5-99de-dd2da759617d', 'SYSTEM_STAGENAME': '__default', 'SYSTEM_TASKDEFINITIONSURI': 'https://dev.azure.com/explosion-ai/', 'SYSTEM_TASKDISPLAYNAME': 'Generate JSONL (Windows)', 'SYSTEM_TASKINSTANCEID': 'd4997dda-70a7-5ff3-3edd-fa7524db0f8f', 'SYSTEM_TASKINSTANCENAME': 'CmdLine5', 'SYSTEM_TEAMFOUNDATIONCOLLECTIONURI': 'https://dev.azure.com/explosion-ai/', 'SYSTEM_TEAMFOUNDATIONSERVERURI': 'https://dev.azure.com/explosion-ai/', 'SYSTEM_TEAMPROJECT': 'Public', 'SYSTEM_TEAMPROJECTID': '5c6613e9-6ccf-48bd-81de-dbc3b0a6f957', 'SYSTEM_TIMELINEID': '5471f6a2-5d2d-4ea1-bf2f-6682941b17de', 'SYSTEM_TOTALJOBSINPHASE': '3', 'SYSTEM_WORKFOLDER': 'D:\\\\a', 'TASK_DISPLAYNAME': 'Generate JSONL (Windows)', 'TASK_PUBLISHTELEMETRY': 'True', 'TASK_SKIPTRANSLATORFORCHECKOUT': 'False', 'TEMP': 'C:\\\\Users\\\\VSSADM~1\\\\AppData\\\\Local\\\\Temp', 'TERM': 'xterm-256color', 'TF_BUILD': 'True', 'TMP': 'C:\\\\Users\\\\VSSADM~1\\\\AppData\\\\Local\\\\Temp', 'TMPDIR': 'C:\\\\Users\\\\VSSADM~1\\\\AppData\\\\Local\\\\Temp', 'USEPYTHONVERSION_PYTHONLOCATION': 'C:\\\\hostedtoolcache\\\\windows\\\\Python\\\\3.9.13\\\\x64', 'USERDOMAIN': 'fv-az618-395', 'USERDOMAIN_ROAMINGPROFILE': 'fv-az618-395', 'USERNAME': 'VssAdministrator', 'USERPROFILE': 'C:\\\\Users\\\\VssAdministrator', 'USE_GIT_LONG_PATHS': 'true', 'USE_LATEST_GIT_VERSION': 'true', 'USE_MSAL': 'true', 'USE_MSDEPLOY_TOKEN_AUTH': 'true', 'VCPKG_INSTALLATION_ROOT': 'C:\\\\vcpkg', 'VSTSAGENT_CONTINUE_AFTER_CANCEL_PROCESSTREEKILL_ATTEMPT': 'true', 'VSTSAGENT_DOCKER_ACTION_RETRIES': 'true', 'VSTS_AGENT_PERFLOG': 'c:\\\\vsts\\\\perflog', 'VSTS_PROCESS_LOOKUP_ID': 'vsts_1a8accd9-c4cc-417c-b11d-eed7c6b9f10a', 'WINDIR': 'C:\\\\Windows', 'WIX': 'C:\\\\Program Files (x86)\\\\WiX Toolset v3.14\\\\', '_': 'C:/hostedtoolcache/windows/Python/3.9.13/x64/python', 'AGENT.JOBSTATUS': 'Succeeded', 'NPM_CONFIG_PREFIX': 'C:\\\\npm\\\\prefix'}\n",
      "      [COMMAND] C:\\Program Files\\LLVM\\bin\\clang.exe -c C:\\Windows\\Temp\\pip-install-alzafcbt\\blis_0067fe95e0dc48cbb5fcaa4f0e5415e5\\blis\\_src\\config\\bulldozer\\bli_cntx_init_bulldozer.c -o C:\\WINDOWS\\TEMP\\tmpzlo0eig6\\bli_cntx_init_bulldozer.o -O3 -std=c99 -D_POSIX_C_SOURCE=200112L -DBLIS_VERSION_STRING=\"0.7.0\" -DBLIS_IS_BUILDING_LIBRARY -Iinclude\\windows-x86_64 -I.\\frame\\3\\ -I.\\frame\\ind\\ukernels\\ -I.\\frame\\3\\ -I.\\frame\\1m\\ -I.\\frame\\1f\\ -I.\\frame\\1\\ -I.\\frame\\include -IC:\\Windows\\Temp\\pip-install-alzafcbt\\blis_0067fe95e0dc48cbb5fcaa4f0e5415e5\\blis\\_src\\include\\windows-x86_64\n",
      "      error: [WinError 2] The system cannot find the file specified\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for blis\n",
      "ERROR: Failed to build installable wheels for some pyproject.toml based projects (blis)\n"
     ]
    }
   ],
   "source": [
    "%pip install spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spacy or the model 'en_core_web_sm' is not available.\n",
      "To install spacy: pip install spacy\n",
      "To download the model: python -m spacy download en_core_web_sm\n"
     ]
    }
   ],
   "source": [
    "# Try to use spacy if available\n",
    "try:\n",
    "    import spacy\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    print(\"Spacy loaded successfully!\")\n",
    "except (ImportError, OSError):\n",
    "    print(\"Spacy or the model 'en_core_web_sm' is not available.\")\n",
    "    print(\"To install spacy: pip install spacy\")\n",
    "    print(\"To download the model: python -m spacy download en_core_web_sm\")\n",
    "    nlp = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spacy not available, using NLTK tokenization instead\n"
     ]
    }
   ],
   "source": [
    "# Try to use spacy for tokenization if available\n",
    "if nlp is not None:\n",
    "    doc1 = nlp(sent5)\n",
    "    doc2 = nlp(sent6)\n",
    "    doc3 = nlp(sent7)\n",
    "    doc4 = nlp(sent1)\n",
    "    print(\"Tokenization with spaCy successful!\")\n",
    "else:\n",
    "    print(\"Spacy not available, using NLTK tokenization instead\")\n",
    "    # Use NLTK tokenization as a fallback\n",
    "    import nltk\n",
    "    try:\n",
    "        nltk.data.find('tokenizers/punkt')\n",
    "    except LookupError:\n",
    "        print(\"Downloading NLTK punkt tokenizer...\")\n",
    "        nltk.download('punkt')\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    doc1 = word_tokenize(sent5)\n",
    "    doc2 = word_tokenize(sent6)\n",
    "    doc3 = word_tokenize(sent7)\n",
    "    doc4 = word_tokenize(sent1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'am', 'going', 'to', 'visit', 'delhi', '!']\n"
     ]
    }
   ],
   "source": [
    "# Display tokens if available\n",
    "if 'doc4' in locals():\n",
    "    print(doc4)\n",
    "else:\n",
    "    print(\"doc4 is not defined. Run the previous cell first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "am\n",
      "going\n",
      "to\n",
      "visit\n",
      "delhi\n",
      "!\n"
     ]
    }
   ],
   "source": [
    "# Print tokens if available\n",
    "if 'doc4' in locals():\n",
    "    for token in doc4:\n",
    "        print(token)\n",
    "else:\n",
    "    print(\"doc4 is not defined. Run the previous cells first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>lemmatized_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one review mention watch oz episod youll hook ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>one review mention watch oz episod youll hook ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonder littl product film techniqu unassum old...</td>\n",
       "      <td>positive</td>\n",
       "      <td>wonder littl product film techniqu unassum old...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought wonder way spend time hot summer weeke...</td>\n",
       "      <td>positive</td>\n",
       "      <td>thought wonder way spend time hot summer weeke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basic there famili littl boy jake think there ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>basic there famili littl boy jake think there ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei love time money visual stun film...</td>\n",
       "      <td>positive</td>\n",
       "      <td>petter mattei love time money visual stun film...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  \\\n",
       "0  one review mention watch oz episod youll hook ...  positive   \n",
       "1  wonder littl product film techniqu unassum old...  positive   \n",
       "2  thought wonder way spend time hot summer weeke...  positive   \n",
       "3  basic there famili littl boy jake think there ...  negative   \n",
       "4  petter mattei love time money visual stun film...  positive   \n",
       "\n",
       "                                   lemmatized_review  \n",
       "0  one review mention watch oz episod youll hook ...  \n",
       "1  wonder littl product film techniqu unassum old...  \n",
       "2  thought wonder way spend time hot summer weeke...  \n",
       "3  basic there famili littl boy jake think there ...  \n",
       "4  petter mattei love time money visual stun film...  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
